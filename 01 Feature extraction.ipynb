{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb86187",
   "metadata": {},
   "source": [
    "____________________\n",
    "<h3><b>1. Feature extraction</b></h3>\n",
    "\n",
    "____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e300257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning (sklearn, tensorflow, keras)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf #tf version is 1.12\n",
    "import tensorflow_hub as hub #hub version is 0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936ed15",
   "metadata": {},
   "source": [
    "_____________________\n",
    "><h5><b>1.2. Images preprocessing</b></h5>\n",
    "\n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c680ba4",
   "metadata": {},
   "source": [
    "Here I extract the features directly from keras generators separately for train, validation and test set. The extracted features are then saved in npz files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa0d6e",
   "metadata": {},
   "source": [
    "_____________\n",
    "> <b>Train</b>\n",
    "\n",
    "__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1863ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "generator_extraction = ImageDataGenerator(rescale=1/255, dtype=np.float32)#since I will perform a feature extraction with a pretrained network I don't have a reason to add parameters for data augmentation\n",
    "#note:this 'generator_extraction' will be the same for validation and test set since there is no data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2407cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "trainset = generator_extraction.flow_from_directory(\n",
    "    os.path.join('train'), batch_size=280, target_size=(224, 224), color_mode='rgb', \n",
    "    interpolation='bilinear',#bilinear is the default but better to outline it\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57800ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images train: (280, 224, 224, 3)\n",
      "Batch labels train: (280, 6)\n"
     ]
    }
   ],
   "source": [
    "batch_imgs_train, batch_labels_train = trainset.next()#this will be usefull later to plot the images\n",
    "print('Batch images train:', batch_imgs_train.shape) \n",
    "print('Batch labels train:', batch_labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2987f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe to summarize the train data    \n",
    "num = trainset.classes\n",
    "num = np.bincount(num)\n",
    "\n",
    "classes = trainset.class_indices\n",
    "train_raw_df = pd.DataFrame(list(classes.items()),columns = ['classes', 'null']) \n",
    "train_raw_df.drop('null', axis=1, inplace = True)#this removes an extra column\n",
    "train_raw_df['images_in_class'] = num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "736ab69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images sum: 280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>images_in_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bike</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motorcycle</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truck</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>van</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classes  images_in_class\n",
       "0        bike               66\n",
       "1         car               64\n",
       "2  motorcycle               51\n",
       "3       other               32\n",
       "4       truck               42\n",
       "5         van               25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('total images sum:', train_raw_df.images_in_class.sum())\n",
    "train_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d34fe65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the classes distribution in the train data\n",
    "plt.bar(train_raw_df.classes, train_raw_df.images_in_class)\n",
    "plt.xlabel('Classes', fontsize=20)\n",
    "plt.ylabel('Images number', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da12744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # Download module\n",
    "    module_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'\n",
    "    feature_extractor = hub.Module(module_url)\n",
    "\n",
    "    # Create input placeholder\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 3])\n",
    "\n",
    "    # A node with the features\n",
    "    imgs_features = feature_extractor(input_imgs)\n",
    "\n",
    "    # Collect initializers\n",
    "    init_op = tf.group([\n",
    "        tf.global_variables_initializer(), tf.tables_initializer()\n",
    "    ])\n",
    "\n",
    "img_graph.finalize() #make the graph \"read-only\"\n",
    "\n",
    "#if the following error appears \n",
    "#RuntimeError: Missing implementation that supports: loader(*('C:\\\\Users\\\\matfr\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\adfe0cf8d843e3588bfb9602e32a718b12212904',), **{})\n",
    "#just delete the folder at the indicated path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172bc9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 1280)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a session\n",
    "sess = tf.Session(graph=img_graph)\n",
    "\n",
    "# Initialize it\n",
    "sess.run(init_op)\n",
    "\n",
    "# Extract features\n",
    "features_train = sess.run(imgs_features, feed_dict={input_imgs: batch_imgs_train})#ensure that the proper data are fed to the graph\n",
    "features_train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9b998",
   "metadata": {},
   "source": [
    "_______________\n",
    "> <b>Validation</b>\n",
    "\n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fe6d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 139 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "valset = generator_extraction.flow_from_directory(\n",
    "    os.path.join('valid'), batch_size=139, target_size=(224, 224), color_mode='rgb',\n",
    "    interpolation='bilinear',#bilinear is the default but better to outline it\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684b4176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images validation: (139, 224, 224, 3)\n",
      "Batch labels validation: (139, 6)\n"
     ]
    }
   ],
   "source": [
    "batch_imgs_val, batch_labels_val = valset.next()\n",
    "print('Batch images validation:', batch_imgs_val.shape) \n",
    "print('Batch labels validation:', batch_labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86830b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 1280)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a session\n",
    "sess = tf.Session(graph=img_graph)\n",
    "\n",
    "# Initialize\n",
    "sess.run(init_op)\n",
    "\n",
    "# Extract features\n",
    "features_validation = sess.run(imgs_features, feed_dict={input_imgs: batch_imgs_val})#ensure that the proper data are fed to the graph\n",
    "features_validation.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f7cb8",
   "metadata": {},
   "source": [
    "____________\n",
    "> <b>Test</b>\n",
    "\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81bbcf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "testset = generator_extraction.flow_from_directory(\n",
    "    os.path.join('test'), batch_size=50, target_size=(224, 224), color_mode='rgb',\n",
    "    interpolation='bilinear',#bilinear is the default but better to outline it\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34031de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images test: (50, 224, 224, 3)\n",
      "Batch labels test: (50, 6)\n"
     ]
    }
   ],
   "source": [
    "batch_imgs_test, batch_labels_test = testset.next()\n",
    "print('Batch images test:', batch_imgs_test.shape) \n",
    "print('Batch labels test:', batch_labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4652271c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1280)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a session\n",
    "sess = tf.Session(graph=img_graph)\n",
    "\n",
    "# Initialize\n",
    "sess.run(init_op)\n",
    "\n",
    "# Extract features\n",
    "features_test = sess.run(imgs_features, feed_dict={input_imgs: batch_imgs_test})#ensure that the proper data are fed to the graph\n",
    "features_test.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762da05",
   "metadata": {},
   "source": [
    "_____________\n",
    "> <b>1.3. Save high-level features</b>\n",
    "\n",
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a366f3f",
   "metadata": {},
   "source": [
    "<br>Here I will save the the high-level features as npz files. Each npz file will contain different arrays:</br>\n",
    "- features (features_train, features_validation, features_test)\n",
    "- labels as integers (trainset.classes, valset.classes, testset.classes)\n",
    "- the original preprocessed images ready to be plotted (batch_imgs_train, batch_imgs_val, batch_imgs_test)\n",
    "- the images path name (train_imgs_path, validation_imgs_path, test_imgs_path)\n",
    "\n",
    "<br>important: there is not shuffling in the data meaning that there is have a 1:1 correspondence across data (e.g. [0] in features_train will correspond to -> trainset.classes[0] -> batch_imgs_train[0] -> train_imgs_path[0]).</br>\n",
    "\n",
    "First, I still need to extract the path names before saving the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75a19af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_imgs_path = []\n",
    "\n",
    "directory=os.listdir('train')\n",
    "for each in directory:\n",
    "    currentFolder = 'train/' + each\n",
    "    for i, file in enumerate (os.listdir(currentFolder)[0:]):\n",
    "        fullpath = currentFolder+ \"/\" + file\n",
    "        train_imgs_path.append(fullpath)\n",
    "        \n",
    "#turn it into np array\n",
    "train_imgs_path = np.array(train_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0119d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "valid_imgs_path = []\n",
    "\n",
    "directory=os.listdir('valid')\n",
    "for each in directory:\n",
    "    currentFolder = 'valid/' + each\n",
    "    for i, file in enumerate (os.listdir(currentFolder)[0:]):\n",
    "        fullpath = currentFolder+ \"/\" + file\n",
    "        valid_imgs_path.append(fullpath)\n",
    "\n",
    "#turn it into np array\n",
    "valid_imgs_path = np.array(valid_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4be4b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "test_imgs_path = []\n",
    "\n",
    "directory=os.listdir('test')\n",
    "for each in directory:\n",
    "    currentFolder = 'test/' + each\n",
    "    for i, file in enumerate (os.listdir(currentFolder)[0:]):\n",
    "        fullpath = currentFolder+ \"/\" + file\n",
    "        test_imgs_path.append(fullpath)\n",
    "        \n",
    "#turn it into np array\n",
    "test_imgs_path = np.array(test_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836b9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('features_mobilenet_v2.npz',\n",
    "         #features\n",
    "         train_hl = features_train, #_hl stands for high-Level\n",
    "         validation_hl = features_validation,\n",
    "         test_hl = features_test,\n",
    "         #labels\n",
    "         labels_train = trainset.classes,\n",
    "         labels_validation = valset.classes,\n",
    "         labels_test = testset.classes,\n",
    "         #imgs\n",
    "         train_imgs = batch_imgs_train,\n",
    "         validation_imgs = batch_imgs_val,\n",
    "         test_imgs = batch_imgs_test,\n",
    "         #paths\n",
    "         train_imgs_path = train_imgs_path,\n",
    "         valid_imgs_path = valid_imgs_path,\n",
    "         test_imgs_path = test_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e31dc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (280, 1280) labels: (280,)\n",
      "X_val: (139, 1280) labels: (139,)\n",
      "X_test: (50, 1280) labels: (50,)\n",
      "train_imgs: (280, 224, 224, 3) validation_imgs: (139, 224, 224, 3) test_imgs: (50, 224, 224, 3)\n",
      "train_imgs_path: (280,) valid_imgs_path: (139,) test_imgs_path: (50,)\n"
     ]
    }
   ],
   "source": [
    "# reload the data (this is not necessary but defines once and for all the set names)\n",
    "with np.load('features_mobilenet_v2.npz', allow_pickle=False) as npz_file:\n",
    "    #features\n",
    "    X_train = npz_file['train_hl']\n",
    "    X_val = npz_file['validation_hl']\n",
    "    X_test = npz_file['test_hl']\n",
    "    #labels\n",
    "    y_train = npz_file['labels_train']\n",
    "    y_val = npz_file['labels_validation']\n",
    "    y_test = npz_file['labels_test']\n",
    "    #imgs\n",
    "    train_imgs = npz_file['train_imgs']\n",
    "    validation_imgs = npz_file['validation_imgs']\n",
    "    test_imgs = npz_file['test_imgs']\n",
    "    #paths\n",
    "    train_imgs_path = npz_file['train_imgs_path']\n",
    "    valid_imgs_path = npz_file['valid_imgs_path']\n",
    "    test_imgs_path = npz_file['test_imgs_path']\n",
    "    \n",
    "print('X_train:', X_train.shape, 'labels:', y_train.shape) \n",
    "print('X_val:', X_val.shape, 'labels:', y_val.shape) \n",
    "print('X_test:', X_test.shape, 'labels:', y_test.shape) \n",
    "print('train_imgs:', train_imgs.shape, 'validation_imgs:', validation_imgs.shape, 'test_imgs:', test_imgs.shape,)\n",
    "print('train_imgs_path:', train_imgs_path.shape, 'valid_imgs_path:', valid_imgs_path.shape, 'test_imgs_path:', test_imgs_path.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
